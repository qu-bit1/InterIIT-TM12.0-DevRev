{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJH7I9Wukfno"
      },
      "source": [
        "# Llama PIRO\n",
        "\n",
        "This notebook implements the PIRO prompting techinique on the Llama"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5X9CXaDskfnq"
      },
      "source": [
        "##  Importing necessary libraries\n",
        "\n",
        "Ensure that the Python environment you are running this in has all the libraries present in [requirements.txt](requirements.txt).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BSdV3fMZmvCK"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install colab-xterm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQJuXA9DmzdQ",
        "outputId": "3d5ce2b7-bdad-407a-aece-17067c7507b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The colabxterm extension is already loaded. To reload it, use:\n",
            "  %reload_ext colabxterm\n"
          ]
        }
      ],
      "source": [
        "%load_ext colabxterm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_Ug6By3njdX",
        "outputId": "cdce1a04-a87c-4e05-a827-dd8e86ef1ad1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0bCOaLyjkgtL"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install -r requirements_llama_piro.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "SVuj6I2lkfnr"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!curl https://ollama.ai/install.sh | sh  # install ollama\n",
        "!apt-get install lshw\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvcVBWVfkfnr"
      },
      "source": [
        "To start using ollama, run the following on Xterm terminal:\n",
        "\n",
        "```ollama serve```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0NaejnpY8H1"
      },
      "outputs": [],
      "source": [
        "#Launch the xterm terminal\n",
        "%xterm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_7vG5dAkfnt"
      },
      "source": [
        "Download the speciifc model you want to use\n",
        "\n",
        "The following notebook is tested on 2 models :\n",
        "1.  llama2\n",
        "2.  vicuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u88CrCHHZFYt"
      },
      "outputs": [],
      "source": [
        "# Pull the model you want to use\n",
        "!ollama pull llama2   # !ollama pull <Your desired Model>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "zheZ4y1tRqNI"
      },
      "outputs": [],
      "source": [
        "#Importing the necessary libraries\n",
        "import langchain\n",
        "import openai\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "from litellm import completion\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.schema import Document\n",
        "\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.agents import AgentExecutor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTyHhf04yLyi"
      },
      "source": [
        "## OpenAI API Key\n",
        "Set your OpenAI API Key as an environment variable using:\n",
        "\n",
        "```\n",
        "%env OPENAI_API_KEY = <Your API Key>\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "bwFAUjoYR_d4"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OPENAI_API_KEY\"]= \"YOUR_OPENAI_API_KEY\"  # Set your OpenAI API key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6k9lp2XVyPvl"
      },
      "source": [
        "## Loading the API documentation and usage examples\n",
        "\n",
        "The required datasets [.json] -\n",
        "- API/Tool Descriptions (api_desc.json)\n",
        "- Tool Usage Example (examples.json)\n",
        "- Queries (PS_queries.json)\n",
        "  \n",
        "  These can be loaded either by\n",
        "  1. Uploading the datasets on google drive and using its id to use `gdown` method (as shown).\n",
        "  2. By directly uploading the datasets to the runtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dWMBxPdMKu4"
      },
      "outputs": [],
      "source": [
        "!gdown 1gG6Ghpkjxqz7vlPjCs2pTdmOSqjt0EIM\n",
        "!gdown 1nJZpWHRdowbdzdRI7ylb1RrZUV_2E6k9\n",
        "!gdown 1JCjW2f0fTsL6W7r7QjQO2FrwKNUj37ao"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2uqvxUCaQOju"
      },
      "outputs": [],
      "source": [
        "documentation_file_path = '/content/api_desc.json'\n",
        "with open(documentation_file_path, 'r') as file:\n",
        "    documentation = json.load(file)\n",
        "\n",
        "\n",
        "examples_file_path = '/content/examples.json'\n",
        "with open(examples_file_path, 'r') as file:\n",
        "    examples = json.load(file)\n",
        "\n",
        "\n",
        "queries_file_path = '/content/PS_queries.json'\n",
        "with open(queries_file_path, 'r') as file:\n",
        "    queries = json.load(file)\n",
        "\n",
        "print(documentation)\n",
        "print(examples)\n",
        "print(queries)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9Lik-sRykSI"
      },
      "source": [
        "# Retrievers for relevant tools and examples\n",
        "\n",
        "- The following section implements the retriever to filter out only the relevant tools and examples from the complete tool description bank and usage examples respectively.\n",
        "- The `get_tools` function returns the set of relevant tools, and their argument on the basis of user query, similarily `get_examples` function returns the set of relevant tool usage examples.\n",
        "- Uses the FAISS index to store the created embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "g-pOfYNCQOhH"
      },
      "outputs": [],
      "source": [
        "# Applying semantic search on the API descriptions\n",
        "API_descriptions = [\n",
        "    Document(page_content=t['description'], metadata={\"index\": i})\n",
        "    for i, t in enumerate(documentation)\n",
        "]\n",
        "API_descriptions_vector_store = FAISS.from_documents(API_descriptions, OpenAIEmbeddings())\n",
        "API_retriever = API_descriptions_vector_store.as_retriever()\n",
        "def get_tools(query):\n",
        "    docs = API_retriever.get_relevant_documents(query)\n",
        "    tools = [documentation[d.metadata[\"index\"]]['tool'] for d in docs]\n",
        "    arguments = [documentation[d.metadata[\"index\"]] for d in docs]\n",
        "    return tools, arguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "5VvFzj11QOdD"
      },
      "outputs": [],
      "source": [
        "#Applying semantic search on the API usage examples\n",
        "\n",
        "API_usage_examples = [\n",
        "    Document(page_content=t['Query'], metadata={\"index\": i})\n",
        "    for i, t in enumerate(examples)\n",
        "]\n",
        "API_usage_examples_vector_score = FAISS.from_documents(API_usage_examples, OpenAIEmbeddings())\n",
        "Examples_retriever = API_usage_examples_vector_score.as_retriever()\n",
        "def get_examples(query):\n",
        "    docs = Examples_retriever.get_relevant_documents(query)\n",
        "    return [examples[d.metadata[\"index\"]] for d in docs]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUzAPjs2zBlr"
      },
      "source": [
        "# PIRO Prompts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mr-6Ntu-kfny"
      },
      "source": [
        "## Planning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "uYMAc9KZQOSE"
      },
      "outputs": [],
      "source": [
        "def get_planning_prompt(query, tools):\n",
        "    planning_template =f\"\"\"\n",
        "    Given a query and a list of APIs with their arguments, find whether the APIs can solve the query or not. If not, return empty list. Else, extract values or variables from the query that correspond to each argument of the tools that needs to be called. If some argument value isn't known, use APIs that can retrieve those argument values. Return a JSON file containing the tools in the order they need to be called. Identify cases where an API argument depends on the output of a previous API call. Replace such arguments with the notation $PREV[i] where 'i' represents the order of the previous API call in the chain.\n",
        "\n",
        "    Query: {query}\n",
        "    APIs: {tools}\n",
        "    Answer:\n",
        "    \"\"\"\n",
        "    return planning_template"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBdAePGbzF9G"
      },
      "source": [
        "## Improvement\n",
        "**Note:** Same template will be used for the reflection process also"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "n6_uCllpxXJv"
      },
      "outputs": [],
      "source": [
        "def get_improvement_prompt(examples, query, solution):\n",
        "    improvement_template = f\"\"\"\n",
        "    Given a list of examples, each containing a query and the corresponding APIs to be called to solve the query, find whether the JSON present in current solution solves the current query.\n",
        "    If yes, modify its format to match with that of solutions in examples and return the modified JSON.\n",
        "    If not, modify the current JSON solution to include necessary tools from list of available tools.\n",
        "    If no solution is available, return a blank list.\n",
        "\n",
        "    Examples : {examples}\n",
        "\n",
        "    Current Query : {query}\n",
        "    Current Solution : {solution}\n",
        "\n",
        "    Answer:\n",
        "    \"\"\"\n",
        "    return improvement_template"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jvxpVXXzK6L"
      },
      "source": [
        "## Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "eLh6N_4zvV9l"
      },
      "outputs": [],
      "source": [
        "def get_optimization_prompt(query, solution, tools):\n",
        "    optimization_template = f\"\"\"\n",
        "    Given a query, solution and available APIs, optimize the number of APIs calls in the solution. Do not use API calls unless absolutely necessary. Look for redundancy and check for mistakes in the combination of API calls. Return current solution if no changes are necessary.\n",
        "\n",
        "    Current Query : {query}\n",
        "    Current Solution : {solution}\n",
        "    Available APIs : {tools}\n",
        "    Final solution (same format as current solution):\n",
        "    \"\"\"\n",
        "    return optimization_template"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Irgbw0zvybAV"
      },
      "source": [
        "# Execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "dO0_lVkskfn0"
      },
      "outputs": [],
      "source": [
        "#Creating empty dataframes to store the results\n",
        "df2 = pd.DataFrame(columns=['query', 'f_output','time'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "X5qS0oFiagJj"
      },
      "outputs": [],
      "source": [
        "def ask_llm(prompt):\n",
        "    # Function to interact with the Llama model and get the response\n",
        "    response = completion(\n",
        "            model=\"ollama/llama2\",\n",
        "            messages = [{\"content\": prompt,\"role\": \"user\"}],\n",
        "            api_base=\"http://localhost:11434\"\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkSkbxVzkfn0"
      },
      "source": [
        "The `get_result` function return the final predicted output,the total time taken to generate the output.\n",
        "\n",
        "- We chose the top 3 Tool usage examples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "dvZ82zJ0ygEB"
      },
      "outputs": [],
      "source": [
        "def get_result(Query):\n",
        "    start = time.time()\n",
        "\n",
        "    _,Tools = get_tools(Query)\n",
        "    Examples = get_examples(Query)[:3]\n",
        "    planning_prompt = get_planning_prompt(Query, Tools)\n",
        "    Solution = ask_llm(planning_prompt)\n",
        "    print(f\"Output 1: {Solution}\")\n",
        "\n",
        "\n",
        "    improvement_prompt = get_improvement_prompt(Examples, Query, Solution)\n",
        "    Solution = ask_llm(improvement_prompt)\n",
        "    print(f\"Output 2: {Solution}\")\n",
        "\n",
        "    optimization_prompt = get_optimization_prompt(Query, Solution, Tools)\n",
        "    Solution = ask_llm(optimization_prompt)\n",
        "    print(f\"Output 3: {Solution}\")\n",
        "\n",
        "    end = time.time()\n",
        "\n",
        "    time_taken = end - start\n",
        "    return Solution, time_taken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkAkam08beEU"
      },
      "outputs": [],
      "source": [
        "#Running the pipeline on the queries\n",
        "for query in queries:\n",
        "  f_output ,time_taken = get_result(query)\n",
        "  f_output = f_output.strip(\"```\").lstrip(\"json\")\n",
        "  df2 = df2.append({'query': query, 'f_output': f_output, 'time': time_taken}, ignore_index=True)\n",
        "  time.sleep(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQaEymZ9kfn1"
      },
      "outputs": [],
      "source": [
        "df2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FIJLVC69kfn1"
      },
      "outputs": [],
      "source": [
        "#Exporting the results to a xlsx file\n",
        "df2.to_excel('PS_results.xlsx')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
