{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvOM1daHyHAD"
      },
      "source": [
        "##  Importing necessary libraries\n",
        "\n",
        "Ensure that the Python environment you are running this in has all the libraries present in [requirements.txt](requirements.txt).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zheZ4y1tRqNI"
      },
      "outputs": [],
      "source": [
        "import langchain\n",
        "import openai\n",
        "import json\n",
        "import os\n",
        "import pandas as pd\n",
        "import tiktoken\n",
        "import time\n",
        "\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.schema import Document\n",
        "\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.callbacks import get_openai_callback\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.agents import AgentExecutor\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.schema import StrOutputParser\n",
        "from langchain.chat_models import ChatOpenAI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTyHhf04yLyi"
      },
      "source": [
        "## OpenAI API Key\n",
        "\n",
        "\n",
        "To set the OPENAI_API_KEY as an environment variable run the following command:\n",
        "```\n",
        "export OPENAI_API_KEY = <Your API Key>\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mTYLcj0quRT4"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OPENAI_API_KEY\"]= <YOUR_OPENAI_API_KEY>  # Set your OpenAI API key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6k9lp2XVyPvl"
      },
      "source": [
        "## Loading the API documentation and usage examples\n",
        "\n",
        "The required datasets [.json] -\n",
        "- API/Tool Descriptions (api_desc.json)\n",
        "- Tool Usage Example (examples.json)\n",
        "- Queries (PS_queries.json)\n",
        "  \n",
        "  These can be loaded either by\n",
        "  1. Uploading the datasets on google drive and using its id to use `gdown` method (as shown).\n",
        "  2. By directly uploading the datasets to the runtime\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fe2enqW0XPFt",
        "outputId": "4e1d2e6f-031e-4ea8-eda0-f9e51432d408"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1gG6Ghpkjxqz7vlPjCs2pTdmOSqjt0EIM\n",
            "To: /content/api_desc.json\n",
            "100% 8.81k/8.81k [00:00<00:00, 25.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1nJZpWHRdowbdzdRI7ylb1RrZUV_2E6k9\n",
            "To: /content/examples.json\n",
            "100% 6.71k/6.71k [00:00<00:00, 22.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1JCjW2f0fTsL6W7r7QjQO2FrwKNUj37ao\n",
            "To: /content/PS_queries.json\n",
            "100% 1.99k/1.99k [00:00<00:00, 9.05MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 1gG6Ghpkjxqz7vlPjCs2pTdmOSqjt0EIM\n",
        "!gdown 1nJZpWHRdowbdzdRI7ylb1RrZUV_2E6k9\n",
        "!gdown 1JCjW2f0fTsL6W7r7QjQO2FrwKNUj37ao"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uqvxUCaQOju",
        "outputId": "0528c828-f911-4533-ad95-f52d635928c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'tool': 'works_list', 'description': 'Returns a list of work items matching the request', 'arguments': [{'argument_name': ' applies_to_part', 'argument_description': 'Filters for work belonging to any of the provided parts', 'argument_type': 'array of strings', 'examples': ['FEAT-123', 'ENH-123', 'PROD-123', 'CAPL-123']}, {'argument_name': 'created_by', 'argument_description': 'Filters for work created by any of these users', 'argument_type': 'array of strings', 'examples': ['DEVU-123']}, {'argument_name': 'issue.priority', 'argument_description': 'Filters for issues with any of the provided priorities. Allowed values: p0, p1, p2,p3', 'argument_type': 'array of strings', 'examples': []}, {'argument_name': 'issue.rev_orgs', 'argument_description': 'Filters for issues with any of the provided Rev organizations', 'argument_type': 'array of strings', 'examples': ['REV-123']}, {'argument_name': 'limit', 'argument_description': \"The maximum number of works to return. The default is '50'\", 'argument_type': 'integer (int32)', 'examples': []}, {'argument_name': 'owned_by', 'argument_description': 'Filters for work owned by any of these users', 'argument_type': 'array of strings', 'examples': ['DEVU-123']}, {'argument_name': 'stage.name', 'argument_description': 'Filters for records in the provided stage(s) by name', 'argument_type': 'array of strings', 'examples': []}, {'argument_name': 'ticket.needs_response', 'argument_description': 'Filters for tickets that need a response', 'argument_type': 'boolean', 'examples': []}, {'argument_name': 'ticket.rev_org', 'argument_description': 'Filters for tickets associated with any of the provided Rev organizations', 'argument_type': 'array of strings', 'examples': ['REV-123']}, {'argument_name': 'ticket.severity', 'argument_description': 'Filters for tickets with any of the provided severities. Allowed values:blocker,high, low, medium', 'argument_type': 'array of strings', 'examples': []}, {'argument_name': 'ticket.source_channel', 'argument_description': 'Filters for tickets with any of the provided source channels', 'argument_type': 'array of strings', 'examples': []}, {'argument_name': 'ticket.source_channel', 'argument_description': 'Filters for tickets with any of the provided source channels', 'argument_type': 'array of strings', 'examples': []}, {'argument_name': 'type', 'argument_description': 'Filters for work of the provided types. Allowed values issue, ticket, task', 'argument_type': 'array of strings', 'examples': []}]}, {'tool': 'summarize_objects', 'description': 'Summarizes a list of objects. The logic of how to summarize a particular object type is an internal implementation detail.', 'arguments': [{'argument_name': 'objects', 'argument_description': 'List of objects to summarize', 'argument_type': 'array of objects', 'examples': []}]}, {'tool': 'prioritize_objects', 'description': 'Summarizes a list of objects. The logic of how to summarize a particular object type is an internal implementation detail.', 'arguments': [{'argument_name': 'objects', 'argument_description': 'List of objects to summarize', 'argument_type': 'array of objects', 'examples': []}]}, {'tool': 'add_work_items_to_sprint', 'description': 'Adds the given work items to the sprint', 'arguments': [{'argument_name': 'work_ids', 'argument_description': 'A list of work item IDs to be added to the sprint.', 'argument_type': 'array of strings', 'examples': []}, {'argument_name': 'sprint_id', 'argument_description': 'The ID of the sprint to which the work items should be added', 'argument_type': 'str', 'examples': []}]}, {'tool': 'get_sprint_id', 'description': 'Returns the ID of the current sprint', 'arguments': [{'argument_name': '', 'argument_description': '', 'argument_type': '', 'examples': []}]}, {'tool': 'get_similar_work_items', 'description': 'Returns a list of work items that are similar to the given work item', 'arguments': [{'argument_name': 'work_id', 'argument_description': 'The ID of the work item for which you want to find similar items', 'argument_type': 'string', 'examples': []}]}, {'tool': 'search_object_by_name', 'description': 'Given a search string, returns the id of a matching object in the system of record. If multiple matches are found, it returns the one where the confidence is highest.', 'arguments': [{'argument_name': 'query', 'argument_description': 'The search string, could be for example customer’s name, part name, user name.', 'argument_type': 'string', 'examples': []}]}, {'tool': 'search_object_by_name', 'description': 'Given a search string, returns the id of a matching object in the system of record. If multiple matches are found, it returns the one where the confidence is highest.', 'arguments': [{'argument_name': 'query', 'argument_description': 'The search string, could be for example customer’s name, part name, user name.', 'argument_type': 'string', 'examples': []}]}, {'tool': 'create_actionable_tasks_from_text', 'description': 'Given a search string, returns the id of a matching object in the system of record. If multiple matches are found, it returns the one where the confidence is highest.', 'arguments': [{'argument_name': 'text', 'argument_description': 'The text from which the actionable insights need to be created.', 'argument_type': 'string', 'examples': []}]}, {'tool': 'create_actionable_tasks_from_text', 'description': 'Given a search string, returns the id of a matching object in the system of record. If multiple matches are found, it returns the one where the confidence is highest.', 'arguments': [{'argument_name': 'text', 'argument_description': 'The text from which the actionable insights need to be created.', 'argument_type': 'string', 'examples': []}]}, {'tool': 'who_am_i', 'description': 'Returns the ID of the current user', 'arguments': [{'argument_name': '', 'argument_description': '', 'argument_type': '', 'examples': []}]}]\n",
            "[{'Query': 'Summarize issues similar to don:core:dvrv-us-1:devo/0:issue/1', 'Solution': [{'tool_name': 'get_similar_work_items', 'arguments': [{'argument_name': 'work_id', 'argument_value': 'don:core:dvrv-us-1:devo/0:issue/1'}]}, {'tool_name': 'summarize_objects', 'arguments': [{'argument_name': 'objects', 'argument_value': '$$PREV[0]'}]}]}, {'Query': 'What is the meaning of life?', 'Solution': []}, {'Query': 'Prioritize my P0 issues and add them to the current sprint', 'Solution': [{'tool_name': 'who_am_i', 'arguments': []}, {'tool_name': 'works_list', 'arguments': [{'argument_name': 'issue.priority', 'argument_value': 'p0'}, {'argument_name': 'owned_by', 'argument_value': '$$PREV[0]'}]}, {'tool_name': 'prioritize_objects', 'arguments': [{'argument_name': 'objects', 'argument_value': '$$PREV[1]'}]}, {'tool_name': 'get_sprint_id', 'arguments': []}, {'tool_name': 'add_work_items_to_sprint', 'arguments': [{'argument_name': 'work_ids', 'argument_value': '$$PREV[2]'}, {'argument_name': 'sprint_id', 'argument_value': '$$PREV[3]'}]}]}, {'Query': 'Summarize high severity tickets from the customer UltimateCustomer', 'Solution': [{'tool_name': 'search_object_by_name', 'arguments': [{'argument_name': 'query', 'argument_value': 'UltimateCustomer'}]}, {'tool_name': 'works_list', 'arguments': [{'argument_name': 'ticket.rev_org', 'argument_value': '$$PREV[0]'}]}, {'tool_name': 'summarize_objects', 'arguments': [{'argument_name': 'objects', 'argument_value': '$$PREV[1]'}]}]}, {'Query': 'What are my all issues in the triage stage under part FEAT-123? Summarize them.', 'Solution': [{'tool_name': 'who_am_i', 'arguments': []}, {'tool_name': 'works_list', 'arguments': [{'argument_name': 'stage.name', 'argument_value': 'triage'}, {'argument_name': 'applies_to_part', 'argument_value': 'FEAT-123'}, {'argument_name': 'owned_by', 'argument_value': '$$PREV[0]'}]}, {'tool_name': 'summarize_objects', 'arguments': [{'argument_name': 'objects', 'argument_value': '$$PREV[1]'}]}]}, {'Query': 'List all high severity tickets coming in from slack from customer Cust123 and generate a summary of them.', 'Solution': [{'tool_name': 'search_object_by_name', 'arguments': [{'argument_name': 'query', 'argument_value': 'Cust123'}]}, {'tool_name': 'works_list', 'arguments': [{'argument_name': 'ticket.rev_org', 'argument_value': '$$PREV[0]'}, {'argument_name': 'ticket.severity', 'argument_value': 'high'}, {'argument_name': 'ticket.source_channel', 'argument_value': 'slack'}]}, {'tool_name': 'summarize_objects', 'arguments': [{'argument_name': 'objects', 'argument_value': '$$PREV[1]'}]}]}, {'Query': 'Get all work items similar to TKT-123, summarize them, create issues from that summary, and prioritize them', 'Solution': [{'tool_name': 'get_similar_work_items', 'arguments': [{'argument_name': 'work_id', 'argument_value': 'TKT-123'}]}, {'tool_name': 'create_actionable_tasks_from_text', 'arguments': [{'argument_name': 'text', 'argument_value': '$$PREV[0]'}]}, {'tool_name': 'prioritize_objects', 'arguments': [{'argument_name': 'objects', 'argument_value': '$$PREV[1]'}]}]}]\n",
            "[\"Add work items 'AB12-XYZ' and 'DEF-456' to sprint 'Sprint123' and retrieve the ID of the current sprint.\", \"Search for work items similar to 'WK-789' and add them to the current sprint, then summarize the list of added work items.\", \"Search for 'Item123', prioritize similar items, and retrieve the ID of the current sprint.\", \"Search for 'Object456', add its ID to 'Sprint789', and find object ID for 'UserXYZ'.\", \"Retrieve work items owned by 'DEVU-123' in 'FEAT-123' and 'PROD-123'. Get similar work items for 'ENH-123'.\", \"Search for 'CAPL-123' and 'PROD-123' by name. Prioritize work items needing a response.\", \"Filter work items in 'REV-123' with severity 'high' and 'medium'. Retrieve work items owned by 'DEVU-123'.\", \"Retrieve work items created by 'DEVU-123' in 'FEAT-123' and 'PROD-123'. Create actionable tasks from text.\", \"Find work items related to 'REV-123'. Get similar work items for 'ENH-123'. Summarize a list of objects.\", \"Search for 'CAPL-123' and 'ENH-123'. Retrieve the current user's ID.\", \"Retrieve a list of all work items associated with the feature 'FEATURE-001'.\", \"Find work items in 'CAPL-123' owned by 'DEVU-123'. Get the current sprint ID.\", \"Filter work items in 'REV-123' with priority 'p0', 'p1', and 'p2'. Retrieve work items owned by 'DEVU-123'.\", \"Find work items in 'CAPL-123' and 'ENH-123'. Create actionable tasks from text.\", \"Add work items 'WK-789A' and 'WK-234B' to sprint 'SPR-123X', and then retrieve the ID of the current sprint.\", \"Find work items similar to 'WK-456C', add them to the current sprint, and then summarize the list of added work items.\", \"Perform a search for an object with the name 'ProjectXYZ'.\", \"Search for work item 'Item_XYZ', prioritize similar items, and retrieve the ID of the current sprint.\", \"Search for object 'Object_ABC', add its ID to sprint 'SPR-890Y', and find object ID for user 'User123'.\", \"Add a new task with ID 'NEW-001' to the sprint named 'Sprint456'.\"]\n"
          ]
        }
      ],
      "source": [
        "#Loading the JSON files as a list\n",
        "\n",
        "documentation_file_path = '/content/api_desc.json'\n",
        "with open(documentation_file_path, 'r') as file:\n",
        "    documentation = json.load(file)\n",
        "\n",
        "\n",
        "examples_file_path = '/content/examples.json'\n",
        "with open(examples_file_path, 'r') as file:\n",
        "    examples = json.load(file)\n",
        "\n",
        "queries_file_path = '/content/PS_queries.json'\n",
        "with open(queries_file_path, 'r') as file:\n",
        "    queries = json.load(file)\n",
        "\n",
        "print(documentation)\n",
        "print(examples)\n",
        "print(queries)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9Lik-sRykSI"
      },
      "source": [
        "## Retrievers for relevant tools and examples\n",
        "\n",
        "- The following section implements the retriever to filter out only the relevant tools and examples from the complete tool description bank and usage examples respectively.\n",
        "- The `get_tools` function returns the set of relevant tools,their arguments and the cost of embeddings based on the user query, similarily `get_examples` function returns the set of relevant tool usage examples with the cost of embeddings.\n",
        "- Additionally, it calculates the number of tokens used to create embeddings.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "D0B0EKc8ShRW"
      },
      "outputs": [],
      "source": [
        "# Inputs a string and returns the number of tokens in the string\n",
        "\n",
        "def num_tokens_from_string(string: str) -> int:\n",
        "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
        "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
        "    num_tokens = len(encoding.encode(string))\n",
        "    return num_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "g-pOfYNCQOhH"
      },
      "outputs": [],
      "source": [
        "#Applying semantic search on the API descriptions\n",
        "\n",
        "API_descriptions = [\n",
        "    Document(page_content=t['description'], metadata={\"index\": i})\n",
        "    for i, t in enumerate(documentation)\n",
        "]\n",
        "API_descriptions_vector_store = FAISS.from_documents(API_descriptions, OpenAIEmbeddings())\n",
        "API_retriever = API_descriptions_vector_store.as_retriever()\n",
        "def get_tools(query):\n",
        "    n_tokens_p = num_tokens_from_string(query)*0.0001/10000\n",
        "    for item in API_descriptions:\n",
        "        n_tokens_p+= num_tokens_from_string(item.page_content)*0.0001/10000\n",
        "    docs = API_retriever.get_relevant_documents(query)\n",
        "    tools = [documentation[d.metadata[\"index\"]]['tool'] for d in docs]\n",
        "    arguments = [documentation[d.metadata[\"index\"]] for d in docs]\n",
        "    return tools, arguments, n_tokens_p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5VvFzj11QOdD"
      },
      "outputs": [],
      "source": [
        "#Applying semantic search on the API usage examples\n",
        "\n",
        "API_usage_examples = [\n",
        "    Document(page_content=t['Query'], metadata={\"index\": i})\n",
        "    for i, t in enumerate(examples)\n",
        "]\n",
        "API_usage_examples_vector_score = FAISS.from_documents(API_usage_examples, OpenAIEmbeddings())\n",
        "Examples_retriever = API_usage_examples_vector_score.as_retriever()\n",
        "def get_examples(query):\n",
        "    n_tokens_p = num_tokens_from_string(query)*0.0001/10000\n",
        "    for item in API_usage_examples:\n",
        "        n_tokens_p+= num_tokens_from_string(item.page_content)*0.0001/10000\n",
        "    docs = Examples_retriever.get_relevant_documents(query)\n",
        "    return [examples[d.metadata[\"index\"]] for d in docs] , n_tokens_p"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KonqpFwOtC61"
      },
      "source": [
        "# PIRO Prompts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUzAPjs2zBlr"
      },
      "source": [
        "## Planning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "uYMAc9KZQOSE"
      },
      "outputs": [],
      "source": [
        "planning_template =\"\"\"\n",
        "Given a query and a list of APIs with their arguments, find whether the APIs can solve the query or not. If not, return empty list. Else, extract values or variables from the query that correspond to each argument of the tools that needs to be called. If some argument value isn't known, use APIs that can retrieve those argument values. Return a JSON file containing the tools in the order they need to be called. Identify cases where an API argument depends on the output of a previous API call. Replace such arguments with the notation $$PREV[i] where 'i' represents the order of the previous API call in the chain.\n",
        "\n",
        "Query: {query}\n",
        "APIs: {tools}\n",
        "\n",
        "Answer:\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBdAePGbzF9G"
      },
      "source": [
        "## Improvement with Examples\n",
        "\n",
        "**Note:** Same template will be used for the reflection process also"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "n6_uCllpxXJv"
      },
      "outputs": [],
      "source": [
        "\n",
        "improvement_template = \"\"\"\n",
        "Given a list of examples, each containing a query and the corresponding APIs to be called to solve the query, find whether the JSON present in current solution solves the current query.\n",
        "If yes, modify its format to match with that of solutions in examples and return the modified JSON.\n",
        "If not, modify the current JSON solution to include necessary tools from list of available tools.\n",
        "If no solution is available, return a blank list.\n",
        "Remember to use double quotes instead of single quotes in JSON output.\n",
        "\n",
        "Examples : {examples}\n",
        "\n",
        "Current Query : {query}\n",
        "Current Solution : {solution}\n",
        "\n",
        "Answer:\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jvxpVXXzK6L"
      },
      "source": [
        "## Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "eLh6N_4zvV9l"
      },
      "outputs": [],
      "source": [
        "optimization_template = \"\"\"\n",
        "Given a query, solution and available APIs, optimize the number of APIs calls in the solution. Do not use API calls unless absolutely necessary. Look for redundancy and check for mistakes in the combination of API calls. Return current solution if no changes are necessary.\n",
        "return only the json.\n",
        "Current Query : {query}\n",
        "Current Solution : {solution}\n",
        "Available APIs : {tools}\n",
        "\n",
        "Final solution (same format as current solution):\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Irgbw0zvybAV"
      },
      "source": [
        "# Execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "atv2CMYclBOL"
      },
      "outputs": [],
      "source": [
        "#Set the model you want to generate the solution(s) with\n",
        "model = \"gpt-3.5-turbo\"\n",
        "\n",
        "#Creating empty dataframes to store the results\n",
        "df = pd.DataFrame(columns=['prompts', 'outputs'])\n",
        "df2 = pd.DataFrame(columns=['query', 'f_output','time','cost'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkP721AstC61"
      },
      "source": [
        "The `get_result` function return the final predicted output,the total time taken to generate the output, and the cost given a user query\n",
        "\n",
        "\n",
        "> Note: To avoid the `RateLimitError` keep the sleep time >10 sec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "dvZ82zJ0ygEB"
      },
      "outputs": [],
      "source": [
        "def get_result(Query):\n",
        "    cost = 0\n",
        "    start = time.time()\n",
        "\n",
        "    #Getting the relevant APIs\n",
        "    _,Tools , c1 = get_tools(Query)\n",
        "    cost+=c1\n",
        "    time.sleep(10)\n",
        "\n",
        "    #Selecting the first 3 relevant examples\n",
        "    Examples, c2 = get_examples(Query)[:3]\n",
        "    cost+=c2\n",
        "\n",
        "\n",
        "    #Planning\n",
        "    planning_prompt = PromptTemplate.from_template(template=planning_template)\n",
        "    planning_chain = planning_prompt | ChatOpenAI(temperature=0.1,model_name=model) | StrOutputParser()\n",
        "    #Calculating the cost of the API calls\n",
        "    with get_openai_callback() as cb:\n",
        "      Solution1 = planning_chain.invoke({\"query\":Query, \"tools\":Tools})\n",
        "      cost+=cb.total_cost\n",
        "\n",
        "    print(f\"Output 1: {Solution1}\")\n",
        "    df.loc[len(df.index)] = [planning_prompt.format(query=Query, tools=Tools), Solution1]\n",
        "    time.sleep(10)\n",
        "\n",
        "\n",
        "    #Improvement\n",
        "    improvement_prompt = PromptTemplate.from_template(template=improvement_template)\n",
        "    improvement_chain = improvement_prompt | ChatOpenAI(temperature=0,model_name=model) | StrOutputParser()\n",
        "    #Calculating the cost of the API calls\n",
        "    with get_openai_callback() as cb:\n",
        "      Solution2 = improvement_chain.invoke({\"examples\":Examples, \"query\":Query, \"solution\":Solution1})\n",
        "      cost+=cb.total_cost\n",
        "\n",
        "    print(f\"Output 2: {Solution2}\")\n",
        "    df.loc[len(df.index)] = [improvement_prompt.format(examples=Examples, query=Query, solution=Solution1), Solution2]\n",
        "    time.sleep(10)\n",
        "\n",
        "\n",
        "    #Reflection\n",
        "    improvement_prompt = PromptTemplate.from_template(template=improvement_template)\n",
        "    improvement_chain = improvement_prompt | ChatOpenAI(temperature=0,model_name=model) | StrOutputParser()\n",
        "    #Calculating the cost of the API calls\n",
        "    with get_openai_callback() as cb:\n",
        "      Solution3 = improvement_chain.invoke({\"examples\":Examples, \"query\":Query, \"solution\":Solution2})\n",
        "      cost+=cb.total_cost\n",
        "\n",
        "    print(f\"Output 2.5: {Solution3}\")\n",
        "    df.loc[len(df.index)] = [improvement_prompt.format(examples=Examples, query=Query, solution=Solution2), Solution3]\n",
        "    time.sleep(10)\n",
        "\n",
        "\n",
        "    #Optimization\n",
        "    optimization_prompt = PromptTemplate.from_template(template=optimization_template)\n",
        "    optimization_chain = optimization_prompt | ChatOpenAI(temperature=0,model_name=model) | StrOutputParser()\n",
        "    #Calculating the cost of the API calls\n",
        "    with get_openai_callback() as cb:\n",
        "      Solution4 = optimization_chain.invoke({\"query\":Query, \"solution\":Solution3, \"tools\":Tools})\n",
        "      cost+=cb.total_cost\n",
        "\n",
        "    print(f\"Output 3: {Solution3}\")\n",
        "    df.loc[len(df.index)] = [optimization_prompt.format(query=Query, solution=Solution3, tools=Tools), Solution4]\n",
        "\n",
        "\n",
        "    end = time.time()\n",
        "    time_taken = end-start\n",
        "\n",
        "\n",
        "    return Solution4 , time_taken -40 , cost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rqe1RhGuMtup"
      },
      "outputs": [],
      "source": [
        "#Running the pipeline on the queries\n",
        "for query in queries:\n",
        "  f_output ,time_taken , cost ,_= get_result(query)\n",
        "  f_output = f_output.strip(\"```\").lstrip(\"json\")\n",
        "  df2 = df2.append({'query': query, 'f_output': f_output, 'time': time_taken, 'cost': cost}, ignore_index=True)\n",
        "  time.sleep(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TXYuJ_1qndHc"
      },
      "outputs": [],
      "source": [
        "df2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtKdMPje3-fK"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LB1Hyy-6tdKR"
      },
      "outputs": [],
      "source": [
        "#Exporting the results to excel files\n",
        "df.to_excel(\"GPT_4_prompts_output.xlsx\", index=False)\n",
        "df2.to_excel(\"GPT_4_query_Output_time_cost.xlsx\", index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
