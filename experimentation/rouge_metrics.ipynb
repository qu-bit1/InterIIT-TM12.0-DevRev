{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ROUGE Metrics\n",
        "### This notebook implements ROUGE metrics on a specific dataset "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##  Importing necessary libraries\n",
        "\n",
        "Ensure that the Python environment you are running this in has all the libraries present in [requirements.txt](requirements.txt).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jRaF7aTX3GZu"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import json\n",
        "from rouge import Rouge\n",
        "import re\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "rouge = Rouge()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Importing the necessary files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OuL-DbKq3Lp4"
      },
      "outputs": [],
      "source": [
        "llm_output_path = 'path_to_llm_output'\n",
        "json_file_path = 'path_to_json_file'\n",
        "llm_output_path_gpt4 = 'path_to_llm_output_gpt4'\n",
        "vicuna_output_path = 'path_to_vicuna_output'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jh7W0m14oyAP"
      },
      "outputs": [],
      "source": [
        "llm_output = pd.read_excel(llm_output_path)\n",
        "gpt4_turbo = pd.read_excel(llm_output_path_gpt4)\n",
        "vicuna_output = pd.read_excel(vicuna_output_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YXouFKpj3mJN"
      },
      "outputs": [],
      "source": [
        "\n",
        "with open(json_file_path, 'r') as json_file:\n",
        "    data = json.load(json_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Manipulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0XYB9WWsD9y"
      },
      "outputs": [],
      "source": [
        "vicuna_output.rename(columns = {'outputs':'f_output'}, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCrltQTzcyJ4"
      },
      "outputs": [],
      "source": [
        "gpt4_turbo = gpt4_turbo[:19]\n",
        "gpt4_turbo = gpt4_turbo.drop([10,16], axis = 'index')\n",
        "gpt4_turbo.index = list(range(17))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "srj4Z6rfrdnX"
      },
      "outputs": [],
      "source": [
        "data_vic = data[:9]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Implementation\n",
        "### Lists all the necessary functions required for calculating ROUGE score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8h6l8oZJ9zf"
      },
      "outputs": [],
      "source": [
        "# Function to calculate the rouge score\n",
        "\n",
        "def get_rouge_score(hyps, refs):\n",
        "    hyp = str(json.loads(hyps))\n",
        "    ref = str(json.loads(refs))\n",
        "    rouge_scores = rouge.get_scores(hyp, ref, avg=True)\n",
        "    return rouge_scores\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to modify the string to our required format\n",
        "\n",
        "def modify(mystring):\n",
        "    mystring = re.sub(\"\\'\",'\\\"',mystring)\n",
        "    mystring = re.sub(\"True\",\"\\\"True\\\"\",mystring)\n",
        "    mystring = re.sub(\"False\",\"\\\"False\\\"\",mystring)\n",
        "    return mystring\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to calculate the rouge score and return it as a dataframe\n",
        "\n",
        "def evaluate(data, llm_output):\n",
        "    df = pd.DataFrame(columns=['rouge-1 r','rouge-1 p','rouge-1 f','rouge-2 r','rouge-2 p','rouge-2 f','rouge-l r','rouge-l p','rouge-l f'])\n",
        "    for i in range(len(data)):\n",
        "        #print(llm_output['query'][i])\n",
        "        hyps = str(data[i]['solutions'])\n",
        "        refs = str(llm_output['f_output'][i])\n",
        "\n",
        "        hyps = modify(hyps)\n",
        "        refs = modify(refs)\n",
        "        result = get_rouge_score(hyps,refs)\n",
        "        df.loc[len(df)]=[result['rouge-1']['r'],result['rouge-1']['r'],result['rouge-1']['r'],\n",
        "                          result['rouge-2']['r'],result['rouge-2']['r'],result['rouge-2']['r'],\n",
        "                          result['rouge-l']['r'],result['rouge-l']['r'],result['rouge-l']['r']]\n",
        "\n",
        "    return df\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "id": "GBKSYafH_BZz",
        "outputId": "1bb74c56-259d-4604-c5b9-8e27156f2534"
      },
      "outputs": [],
      "source": [
        "answer = evaluate(data, llm_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_hyn_gebyvh"
      },
      "outputs": [],
      "source": [
        "answer_gpt4 = evaluate(data, gpt4_turbo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Converting into an excel file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBvNpRr3o_UG"
      },
      "outputs": [],
      "source": [
        "answer.to_excel('gpt3.5_rouge_eval.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4DrEI9jlCeo"
      },
      "outputs": [],
      "source": [
        "answer_gpt4.to_excel('gpt4-turbo-eval-rouge.xlsx')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
